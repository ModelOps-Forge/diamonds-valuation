## üèóÔ∏è Estructura del Proyecto

```text
‚îú‚îÄ‚îÄ data/           # Datasets originales y procesados.
‚îú‚îÄ‚îÄ notebooks/      # An√°lisis exploratorio (EDA) y prototipado.
‚îú‚îÄ‚îÄ src/            # C√≥digo fuente modular (limpieza, ingenier√≠a, entrenamiento).
‚îú‚îÄ‚îÄ models/         # Modelos serializados (archivos .pkl o .h5).
‚îú‚îÄ‚îÄ main.py         # Orquestador principal (Entrenamiento)
‚îú‚îÄ‚îÄ inference.py    # Consumo del modelo (Prediccion)
‚îî‚îÄ‚îÄ requirements.txt # Dependencias del proyecto.

```

## üìä Data Source

Los datasets utilizados en este proyecto provienen de la competici√≥n de Kaggle:
* **Competici√≥n:** [CEUPE - Big Data Analytics](https://www.kaggle.com/competitions/ceupe-big-data-analytics)
* **Dataset:** 
- `diamonds_train.csv` (conjunto para entrenamiento incluido en la secci√≥n de data de la competici√≥n).
- `diamonds_test.csv`
- `sample_submission.csv` 
> **Nota:** Debido a las pol√≠ticas de Kaggle y al peso de los archivos, los datos crudos no se encuentran en este repositorio. Deben descargarse manualmente y colocarse en `data/raw/`.


## üõ†Ô∏è Pipeline de Ingenier√≠a

A diferencia de un an√°lisis convencional, este repositorio implementa un flujo de trabajo estructurado:

1. **Data Cleaning:** Tratamiento de *outliers* en dimensiones cr√≠ticas (x, y, z) y manejo de valores inconsistentes en profundidad y tabla.
2. **Feature Engineering:** Codificaci√≥n de variables categ√≥ricas (*Cut, Color, Clarity*) utilizando mapeos ordinales para capturar la jerarqu√≠a de calidad.
3. **Modeling:** Evaluaci√≥n comparativa entre regresi√≥n lineal m√∫ltiple y modelos basados en ensamble (*Random Forest*).
4. **Validation:** Divisi√≥n de datos mediante Hold-out para una evaluaci√≥n inicial, con planes de implementar K-Fold Cross-Validation durante la fase de optimizaci√≥n de hiperpar√°metros.

## üìä M√©tricas de Rendimiento

El modelo final se eval√∫a bajo las siguientes m√©tricas de regresi√≥n:

| M√©trica | Descripci√≥n | Valor obtenido |
| --- | --- | --- |
| **R¬≤ Score** | Coeficiente de determinaci√≥n | `0.98` |
| **RMSE** | Root Mean Square Error | `$526.24` |
| **MAE** | Mean Absolute Error | `$264.95` |

## üß† Conclusiones y Hallazgos

* **Poder Predictivo:** El modelo alcanza un **R¬≤ de 0.98**, lo que demuestra que las caracter√≠sticas f√≠sicas de los diamantes (x, y, z y quilates) tienen una relaci√≥n matem√°tica casi lineal-exponencial con el precio de mercado.
* **An√°lisis de Error:** El **MAE de $264.95** indica una alta precisi√≥n para el rango medio de precios. Sin embargo, la diferencia con el **RMSE ($526.24)** sugiere que el modelo enfrenta mayores dificultades con los *outliers* (diamantes de extrema rareza o precios muy elevados), donde la variabilidad es mayor.
* **Eficiencia del Pipeline:** Gracias a la arquitectura modular y el uso de formatos **Parquet**, el ciclo completo desde la ingesta hasta la evaluaci√≥n se ejecuta en menos de 10 segundos, permitiendo una iteraci√≥n r√°pida para experimentos de *Fine-tuning*.
* **Jerarqu√≠a Ordinal:** La codificaci√≥n manual de la calidad (*Cut, Color, Clarity*) result√≥ ser superior a una codificaci√≥n simple, confirmando que respetar el conocimiento de dominio del sector joyero mejora la estabilidad del modelo.

A continuaci√≥n se presentan los resultados visuales de la evaluaci√≥n del modelo:

### Comparativa: Real vs. Predicho
Este gr√°fico muestra la alta correlaci√≥n entre las predicciones y los valores reales. La alineaci√≥n con la diagonal confirma un $R^2$ de 0.98.
![Real vs Predicho](reports/figures/real_vs_predicho.png)

### Distribuci√≥n de Residuales
La simetr√≠a de los errores alrededor del cero indica que el modelo es insesgado, aunque las colas del histograma reflejan la presencia de valores at√≠picos en diamantes de alto valor.
![Distribuci√≥n de Errores](reports/figures/distribucion_errores.png)


## Pr√≥ximos Pasos

* [ ] Implementaci√≥n de optimizaci√≥n de hiperpar√°metros con **Optuna**.
* [ ] Creaci√≥n de una API con **FastAPI** para servir el modelo.
* [ ] Desarrollo de una interfaz de usuario en **Streamlit**.


## üöÄ Instalaci√≥n y Uso

Para replicar este entorno de ingenier√≠a, siga estos pasos:

1. **Clonar el repositorio:**
```bash
git clone [https://github.com/ModelOps-Forge/diamonds-valuation.git](https://github.com/ModelOps-Forge/diamonds-valuation.git)

```


2. **Instalar dependencias:**
```bash
pip install -r requirements.txt

```


3. **Ejecutar el pipeline:**
```bash
python main.py

```

## üí° Uso del Modelo (Inferencia)

Una vez ejecutado el pipeline y generados los artefactos en `/models`, puede utilizar el script de inferencia para tasar diamantes individuales:

```python
# Ejemplo r√°pido dentro de inference.py
nuevo_diamante = {
    'quilate': 1.2,
    'corte': 'Premium',
    'color': 'G',
    'claridad': 'VS2',
    'profundidad': 62.0,
    'tabla': 58.0,
    'x': 6.8, 'y': 6.8, 'z': 4.2
}

```
Para ejecutar una prueba:
```python
python inference.py

=============================================
 üíé RESUMEN DE TASACI√ìN DE DIAMANTE üíé 
=============================================
CARACTER√çSTICA       | VALOR               
---------------------------------------------
Quilate              | 0.7                 
Corte                | Ideal               
Color                | E                   
Claridad             | SI1                 
Profundidad          | 61.5                
Tabla                | 55.0                
X                    | 5.72                
Y                    | 5.75                
Z                    | 3.52                
---------------------------------------------
PRECIO ESTIMADO:     | $2,824.09 USD
=============================================
```
---

**Desarrollado con rigor t√©cnico en [ModelOps-Forge**](https://github.com/ModelOps-Forge)
